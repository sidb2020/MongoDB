{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tQ9_z5olLhXk"
   },
   "source": [
    "#Mongo DB Theoretical Questions\n",
    "\n",
    "---\n",
    "\n",
    "#### **1. What are the key differences between SQL and NoSQL databases ?**\n",
    "\n",
    "**Answer:**\n",
    "SQL databases are relational and use structured query language (SQL) to manage data in predefined schemas (tables with fixed columns and types). NoSQL databases like MongoDB are non-relational, use flexible document-based models, and are better suited for unstructured or semi-structured data. SQL excels in consistency and complex joins, while NoSQL offers scalability, high performance, and schema flexibility, ideal for modern, large-scale applications.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. What makes MongoDB a good choice for modern applications ?**\n",
    "\n",
    "**Answer:**\n",
    "MongoDB supports a flexible schema, allowing dynamic and nested documents, which aligns well with agile development and evolving data structures. It handles large volumes of data efficiently, scales horizontally via sharding, and supports powerful features like indexing, aggregation, replication, and transactions. These qualities make it ideal for cloud-native, real-time, and big data applications.\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Explain the concept of collections in MongoDB.**\n",
    "\n",
    "**Answer:**\n",
    "In MongoDB, a collection is analogous to a table in SQL but more flexible. It holds multiple documents (records) with varying structures. Collections do not enforce a schema, allowing documents with different fields. This enables rapid development and easy iteration. Collections are created automatically when the first document is inserted and can be indexed and queried efficiently.\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. How does MongoDB ensure high availability using replication ?**\n",
    "\n",
    "**Answer:**\n",
    "MongoDB uses replica sets to achieve high availability. A replica set is a group of mongod instances that maintain the same dataset. It includes a primary node (which handles writes) and secondary nodes (which replicate data from the primary). If the primary fails, an automatic election promotes a secondary to primary, ensuring minimal downtime.\n",
    "\n",
    "---\n",
    "\n",
    "#### **5. What are the main benefits of MongoDB Atlas ?**\n",
    "\n",
    "**Answer:**\n",
    "MongoDB Atlas is a fully managed cloud database service. It offers automated backups, real-time monitoring, global distribution, scalability, and security features like encryption and access control. Atlas removes the burden of infrastructure management, making it easy to deploy, scale, and maintain MongoDB clusters in AWS, Azure, or GCP.\n",
    "\n",
    "---\n",
    "\n",
    "#### **6. What is the role of indexes in MongoDB, and how do they improve performance ?**\n",
    "\n",
    "**Answer:**\n",
    "Indexes in MongoDB enhance query performance by allowing fast data retrieval without scanning every document. They function similarly to book indexes. Common types include single-field, compound, text, and geospatial indexes. Without indexes, MongoDB must perform full collection scans, which are slower for large datasets.\n",
    "\n",
    "---\n",
    "\n",
    "#### **7. Describe the stages of the MongoDB aggregation pipeline.**\n",
    "\n",
    "**Answer:**\n",
    "The aggregation pipeline processes data through multiple stages, each transforming the input documents. Key stages include:\n",
    "\n",
    "\n",
    "- **match** : filters documents\n",
    "- **group** : groups documents and performs calculations\n",
    "- **project** : reshapes documents\n",
    "- **sort**, **limit**, **skip** : control output order and size\n",
    "- **lookup** : joins collections\n",
    "\n",
    "This allows powerful, SQL-like analytical processing on MongoDB data.\n",
    "\n",
    "---\n",
    "\n",
    "#### **8. What is sharding in MongoDB? How does it differ from replication ?**\n",
    "\n",
    "**Answer:**\n",
    "Sharding splits large datasets across multiple servers (shards) to enable horizontal scaling. Each shard holds a portion of the data. It improves performance and storage capacity. Replication, by contrast, copies data across nodes for redundancy and availability. Sharding spreads the load; replication ensures reliability.\n",
    "\n",
    "---\n",
    "\n",
    "#### **9. What is PyMongo, and why is it used ?**\n",
    "\n",
    "**Answer:**\n",
    "PyMongo is the official Python driver for MongoDB. It allows Python applications to interact with MongoDB databases by providing methods to perform CRUD operations, aggregations, indexing, and connection management. It's essential for building Python-based data pipelines and applications that use MongoDB.\n",
    "\n",
    "---\n",
    "\n",
    "#### **10. What are the ACID properties in the context of MongoDB transactions ?**\n",
    "\n",
    "**Answer:**\n",
    "MongoDB supports ACID (Atomicity, Consistency, Isolation, Durability) properties in multi-document transactions starting from version 4.0. This ensures that either all operations in a transaction succeed or none do (atomicity), maintaining data integrity. It enables use cases like financial systems where data consistency is critical.\n",
    "\n",
    "---\n",
    "\n",
    "#### **11. What is the purpose of MongoDB’s explain() function ?**\n",
    "\n",
    "**Answer:**\n",
    "The **explain()** function analyzes query performance by showing how MongoDB executes a query. It details stages like collection scans, index use, number of documents scanned, and query execution time. This helps developers optimize queries and understand why certain operations may be slow.\n",
    "\n",
    "---\n",
    "\n",
    "#### **12. How does MongoDB handle schema validation ?**\n",
    "\n",
    "**Answer:**\n",
    "While MongoDB is schema-less by default, it supports schema validation using JSON Schema. Validation rules can be defined at the collection level, enforcing required fields, data types, or field patterns. This offers flexibility with control, ensuring data integrity without rigid schemas.\n",
    "\n",
    "---\n",
    "\n",
    "#### **13. What is the difference between a primary and a secondary node in a replica set ?**\n",
    "\n",
    "**Answer:**\n",
    "The primary node in a replica set handles all write operations. Secondary nodes replicate the primary's data and can serve read operations (if enabled). If the primary fails, an automatic election promotes a secondary to become the new primary, maintaining high availability.\n",
    "\n",
    "---\n",
    "\n",
    "#### **14. What security mechanisms does MongoDB provide for data protection ?**\n",
    "\n",
    "**Answer:**\n",
    "MongoDB offers multiple security features:\n",
    "\n",
    "* Authentication (SCRAM, LDAP)\n",
    "* Role-based access control (RBAC)\n",
    "* Encryption at rest and in transit (TLS/SSL)\n",
    "* Auditing and IP whitelisting\n",
    "* Field-level encryption\n",
    "  These help ensure that data is accessed and modified only by authorized users.\n",
    "\n",
    "---\n",
    "\n",
    "#### **15. Explain the concept of embedded documents and when they should be used.**\n",
    "\n",
    "**Answer:**\n",
    "Embedded documents are nested documents stored inside a parent document. They enable fast read/write operations by keeping related data together. They are ideal for one-to-few relationships (e.g., a blog post with comments). However, they can increase document size and complexity if used excessively.\n",
    "\n",
    "---\n",
    "\n",
    "#### **16. What is the purpose of MongoDB’s $lookup stage in aggregation ?**\n",
    "\n",
    "**Answer:**\n",
    "The **$lookup** stage performs a left outer join between collections, allowing you to combine documents based on matching fields. It's useful for denormalized joins like fetching user details from a **users** collection for each **order** in an **orders** collection — similar to SQL joins.\n",
    "\n",
    "---\n",
    "\n",
    "#### **17. What are some common use cases for MongoDB ?**\n",
    "\n",
    "**Answer:**\n",
    "MongoDB is ideal for:\n",
    "\n",
    "* Real-time analytics\n",
    "* Content management systems\n",
    "* IoT applications\n",
    "* Product catalogs\n",
    "* Social media platforms\n",
    "* Mobile and web apps\n",
    "  Its flexibility and scalability make it suitable for handling rapidly changing and large-scale data.\n",
    "\n",
    "---\n",
    "\n",
    "#### **18. What are the advantages of using MongoDB for horizontal scaling ?**\n",
    "\n",
    "**Answer:**\n",
    "MongoDB supports horizontal scaling via sharding, which distributes data across multiple machines. This improves read/write throughput, manages large datasets efficiently, and avoids the limitations of vertical scaling (adding more CPU/RAM to one machine). It’s essential for handling big data workloads.\n",
    "\n",
    "---\n",
    "\n",
    "#### **19. How do MongoDB transactions differ from SQL transactions ?**\n",
    "\n",
    "**Answer:**\n",
    "MongoDB transactions are newer (introduced in v4.0) and support ACID guarantees for multi-document operations. SQL databases offer mature, default ACID transactions across multiple rows/tables. MongoDB transactions are slower than single-document operations and should be used when atomicity across documents is essential.\n",
    "\n",
    "---\n",
    "\n",
    "#### **20. What are the main differences between capped collections and regular collections ?**\n",
    "\n",
    "**Answer:**\n",
    "Capped collections are fixed-size, circular collections that overwrite the oldest data when full. They preserve insertion order and are useful for logging or caching. Regular collections grow dynamically and can be modified freely. Capped collections improve performance for append-only workloads.\n",
    "\n",
    "---\n",
    "\n",
    "#### **21. What is the purpose of the $match stage in MongoDB’s aggregation pipeline ?**\n",
    "\n",
    "The **$match** stage filters documents based on specific conditions, similar to a SQL WHERE clause. It’s often used at the beginning of a pipeline to reduce the number of documents passed to subsequent stages, thereby improving performance and narrowing focus.\n",
    "\n",
    "---\n",
    "\n",
    "#### **22. How can you secure access to a MongoDB database ?**\n",
    "\n",
    "**Answer:**\n",
    "You can secure MongoDB by enabling authentication, using role-based access control, encrypting data in transit with TLS, setting firewall rules, enabling IP whitelisting, and regularly auditing access. MongoDB Atlas simplifies security configuration with built-in tools and alerts.\n",
    "\n",
    "---\n",
    "\n",
    "#### **23. What is MongoDB’s WiredTiger storage engine, and why is it important ?**\n",
    "\n",
    "**Answer:**\n",
    "WiredTiger is MongoDB’s default storage engine. It offers high concurrency, compression, and efficient memory usage. It supports document-level locking and checkpointing for durability. WiredTiger significantly improves write throughput and is crucial for scaling performance-intensive applications.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ko4ogspOTM4A",
    "outputId": "57d92697-c148-4c92-e77a-6a6a45d10033"
   },
   "outputs": [],
   "source": [
    "## Practical Questions\n",
    "#1. Write a Python script to load the Superstore dataset from a CSV file into MongoDB.\n",
    "\n",
    "# Step 1: Import required libraries\n",
    "import pandas as pd\n",
    "from mongita import MongitaClientMemory  # Use in-memory MongoDB-like DB\n",
    "\n",
    "# Step 2: Load the CSV file with encoding fix\n",
    "df = pd.read_csv('/content/superstore.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# Step 3: Create a Mongita client (in-memory)\n",
    "client = MongitaClientMemory()\n",
    "db = client[\"SuperstoreDB\"]\n",
    "collection = db[\"Orders\"]\n",
    "\n",
    "# Step 4: Insert data into the collection\n",
    "data = df.to_dict(orient='records')\n",
    "collection.insert_many(data)\n",
    "\n",
    "print(f\"Successfully inserted {len(data)} documents into the 'Orders' collection.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SFjMdTbSTb97"
   },
   "outputs": [],
   "source": [
    "#2. Retrieve and print all documents from the Orders collection.\n",
    "\n",
    "for doc in collection.find().limit(5):\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a-lUj3_nYluV",
    "outputId": "95d54edc-65d4-4eaa-c1a9-58916de5ce9f"
   },
   "outputs": [],
   "source": [
    "#3. Count and display the total number of documents in the Orders collection.\n",
    "\n",
    "count = collection.count_documents({})\n",
    "print(\"Total number of documents:\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ty6E_w6WZLSX"
   },
   "outputs": [],
   "source": [
    "#4. Write a query to fetch all orders from the \"West\" region.\n",
    "\n",
    "west_orders = collection.find({\"Region\": \"West\"})\n",
    "for order in west_orders:\n",
    "    print(order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yyUUUXUkZVe1"
   },
   "outputs": [],
   "source": [
    "#5. Write a query to find orders where Sales is greater than 500.\n",
    "\n",
    "high_sales = collection.find({\"Sales\": {\"$gt\": 500}})\n",
    "for order in high_sales:\n",
    "    print(order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gm2ZB1tJZm_6",
    "outputId": "0eaf9c11-197c-4e76-c33a-90536ffa7f56"
   },
   "outputs": [],
   "source": [
    "#6. Fetch the top 3 orders with the highest Profit.\n",
    "\n",
    "top_profit_orders = sorted(collection.find(), key=lambda x: x.get(\"Profit\", 0), reverse=True)[:3]\n",
    "for order in top_profit_orders:\n",
    "    print(order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cp1A4qOUZ3nD",
    "outputId": "f5219f0f-dcca-4551-c661-0ead147e033f"
   },
   "outputs": [],
   "source": [
    "#7. Update all orders with Ship Mode as \"First Class\" to \"Premium Class\".\n",
    "\n",
    "result = collection.update_many(\n",
    "    {\"Ship Mode\": \"First Class\"},\n",
    "    {\"$set\": {\"Ship Mode\": \"Premium Class\"}}\n",
    ")\n",
    "print(f\"Updated {result.modified_count} documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JBEnkhwkZ_fu",
    "outputId": "542ca065-e92c-4971-a7fb-8600db6876bb"
   },
   "outputs": [],
   "source": [
    "#8. Delete all orders where Sales is less than 50.\n",
    "\n",
    "result = collection.delete_many({\"Sales\": {\"$lt\": 50}})\n",
    "print(f\"Deleted {result.deleted_count} documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zU8s3EFnaJrQ",
    "outputId": "5aff37da-b63b-4add-f3e2-e77c5381dd7b"
   },
   "outputs": [],
   "source": [
    "#9. Use aggregation to group orders by Region and calculate total sales per region.\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "sales_by_region = defaultdict(float)\n",
    "for doc in collection.find().limit(5):\n",
    "    region = doc[\"Region\"]\n",
    "    sales = doc.get(\"Sales\", 0)\n",
    "    sales_by_region[region] += sales\n",
    "\n",
    "# Display the result\n",
    "for region, total_sales in sales_by_region.items():\n",
    "    print(f\"Region: {region}, Total Sales: {round(total_sales, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Tx0aDPsaRab",
    "outputId": "00516847-5c3c-4883-a85e-fcfefc3d4d53"
   },
   "outputs": [],
   "source": [
    "#10. Fetch all distinct values for Ship Mode from the collection.\n",
    "\n",
    "distinct_ship_modes = set()\n",
    "for doc in collection.find().limit(5):\n",
    "    if \"Ship Mode\" in doc:\n",
    "        distinct_ship_modes.add(doc[\"Ship Mode\"])\n",
    "\n",
    "print(\"Distinct Ship Modes:\", list(distinct_ship_modes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rJZodQtlaa5j",
    "outputId": "a7fa535b-edc2-4f92-bc92-8c53a77c055b"
   },
   "outputs": [],
   "source": [
    "#11. Count the number of orders for each category.\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "category_counts = Counter()\n",
    "for doc in collection.find().limit(5):\n",
    "    category = doc.get(\"Category\")\n",
    "    if category:\n",
    "        category_counts[category] += 1\n",
    "\n",
    "for category, count in category_counts.items():\n",
    "    print(f\"Category: {category}, Order Count: {count}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
